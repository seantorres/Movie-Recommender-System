{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import boto3\n",
    "import fuzzywuzzy\n",
    "import warnings\n",
    "import sklearn\n",
    "import matplotlib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 's3://ads508-imdb-data1'\n",
    "\n",
    "names = pd.read_csv(f'{bucket}/ImdbName.csv')\n",
    "akas = pd.read_csv(f'{bucket}/ImdbTitleAkas.csv')\n",
    "titles = pd.read_csv(f'{bucket}/ImdbTitleBasics.csv')\n",
    "crew = pd.read_csv(f'{bucket}/ImdbTitleCrew.csv')\n",
    "episode = pd.read_csv(f'{bucket}/ImdbTitleEpisode.csv')\n",
    "principals = pd.read_csv(f'{bucket}/ImdbTitlePrincipals.csv')\n",
    "ratings = pd.read_csv(f'{bucket}/ImdbTitleRatings.csv')\n",
    "plots = pd.read_csv(f'{bucket}/movies_initial.csv')\n",
    "netflix = pd.read_csv(f'{bucket}/NetFlix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names.shape, akas.shape, titles.shape, crew.shape, episode.shape, principals.shape, ratings.shape, plots.shape, netflix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_top = netflix.head()\n",
    "#list(netflix.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty dataframe\n",
    "df = pd.DataFrame(columns = ['Netflix', 'IMDB','same'])\n",
    "# filled empty df with titles\n",
    "df['Netflix'] = netflix['title']\n",
    "df['IMDB'] = titles ['primaryTitle']\n",
    "df['same'] = df['Netflix']\n",
    "#df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# why comparing the lists doesnt work \n",
    "#movies={}\n",
    "#for movie in df['same'] :\n",
    "#    if movie in titles ['originalTitle']:\n",
    "#        movies = \"yes\"\n",
    "#    else:\n",
    "#        movies = \"no\"\n",
    "#print (movies)\n",
    "#df['same'] = movies\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count = df['same'].value_counts()\n",
    "#count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy Wuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tconst', 'titletype', 'primarytitle', 'originaltitle', 'isadult',\n",
       "       'startyear', 'endyear', 'runtimeminutes', 'genres'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import pandas\n",
    "\n",
    "\n",
    "dframe1= pd.DataFrame(netflix)\n",
    "dframe2= pd.DataFrame(titles)\n",
    "\n",
    "mat1 = []\n",
    "mat2 = []\n",
    "\n",
    "dframe1.columns.str.lower()\n",
    "dframe2.columns.str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = dframe1['title'].tolist()\n",
    "list2 = dframe2['originalTitle'].tolist()\n",
    "  \n",
    "# taking the threshold as 90\n",
    "threshold = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating through list1 to extract \n",
    "# it's closest match from list2\n",
    "for i in list1:\n",
    "    mat1.append(process.extract(i, list2, limit=2))\n",
    "dframe1['matches'] = mat1\n",
    "  \n",
    "dframe1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating through the closest\n",
    "# matches to filter out the\n",
    "# maximum closest match\n",
    "for j in dframe1['matches']:\n",
    "    for k in j:\n",
    "        \n",
    "        if k[1] >= threshold:\n",
    "            p.append(k[0])\n",
    "              \n",
    "    mat2.append(\",\".join(p))\n",
    "    p = []\n",
    "      \n",
    "# storing the resultant matches \n",
    "# back to dframe1\n",
    "dframe1['matches'] = mat2\n",
    "  \n",
    "dframe1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Compare Example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fuzzywuzzy import fuzz\n",
    "\n",
    "\n",
    "#def Str_cmpr_pct():\n",
    "#Str1 = store1\n",
    "#Str2 = store2\n",
    "#Distance = levenshtein_ratio_and_distance(Str1.lower(),Str2.lower())\n",
    "#print(Distance)\n",
    "#Ratio = levenshtein_ratio_and_distance(Str1.lower(),Str2.lower(),ratio_calc = True)\n",
    "#print(Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Preperation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = merge dframe1 and netflix\n",
    " #   \n",
    " #   header=None,\n",
    "#    usecols=[11],\n",
    "#    names=[ \"description\"],\n",
    "#)\n",
    "\n",
    "#sentences = df1.sentence.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to clean text by removing urls, emojis, html tags and punctuations.\n",
    "\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'', text)\n",
    "\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        '['\n",
    "        u'\\U0001F600-\\U0001F64F'  # emoticons\n",
    "        u'\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n",
    "        u'\\U0001F680-\\U0001F6FF'  # transport & map symbols\n",
    "        u'\\U0001F1E0-\\U0001F1FF'  # flags (iOS)\n",
    "        u'\\U00002702-\\U000027B0'\n",
    "        u'\\U000024C2-\\U0001F251'\n",
    "        ']+',\n",
    "        flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def remove_html(text):\n",
    "    html = re.compile(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    return re.sub(html, '', text)\n",
    "\n",
    "\n",
    "def remove_punct(text):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix['description'] = netflix['description'].apply(lambda x: remove_URL(x))\n",
    "netflix['description'] = netflix['description'].apply(lambda x: remove_emoji(x))\n",
    "netflix['description'] = netflix['description'].apply(lambda x: remove_html(x))\n",
    "netflix['description'] = netflix['description'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots['fullplot'] = plots['fullplot'].apply(lambda x: remove_URL(x))\n",
    "plots['fullplot'] = plots['fullplot'].apply(lambda x: remove_emoji(x))\n",
    "plots['fullplot'] = plots['fullplot'].apply(lambda x: remove_html(x))\n",
    "plots['fullplot'] = plots['fullplot'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Duration Netflix / Boxplot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waiting to combine stuff before normalize"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
